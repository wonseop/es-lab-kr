{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s49gpkvZ7q53"
   },
   "source": [
    "# Multilingual semantic search\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/main/blob/notebooks/search/04-multilingual.ipynb)\n",
    "\n",
    "\n",
    " 이 예에서는 다국어 임베딩 모델을 사용합니다.\n",
    "[multilingual-e5-base](https://huggingface.co/intfloat/multilingual-e5-base)는 혼합된 간단한 데이터세트에서 검색을 수행합니다.\n",
    "언어 문서. 이 모델을 사용하면 두 가지 방법으로 검색할 수 있습니다.\n",
    "  * 여러 언어에 걸쳐(예: 독일어로 된 쿼리를 사용하여 영어로 된 문서 찾기)\n",
    "  * 영어가 아닌 언어 내에서(예: 독일어로 된 문서를 찾기 위해 독일어로 된 쿼리 사용)\n",
    "\n",
    "이 예에서는 밀집 검색만 사용하고 있지만 밀집 검색과 전통적 어휘 검색을 결합하는 것도 가능합니다.\n",
    "하이브리드 검색으로 어휘 다국어 검색에 대한 자세한 내용은 블로그 게시물을 참조하세요.\n",
    "[Elasticsearch의 언어 식별을 이용한 다국어 검색](https://www.elastic.co/blog/multilingual-search-using-언어-identification-in-elasticsearch).\n",
    "\n",
    "사용된 데이터 세트에는 [MIRACL](https://project-miracl.github.io/) 데이터 세트의 Wikipedia 구절 스니펫이 포함되어 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Y01AXpELkygt"
   },
   "source": [
    "# 🧰 Requirements\n",
    "\n",
    "이 예에서는 다음이 필요합니다.\n",
    "\n",
    "- 파이썬 3.6 이상\n",
    "- 최소 **4GB 기계 학습 노드**\n",
    "- [Elastic Python 클라이언트](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/installation.html)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gaTFHLJC-Mgi"
   },
   "source": [
    "# Install packages and initialize the Elasticsearch Python client\n",
    "\n",
    "시작하려면 Python 클라이언트를 사용하여 Elastic 배포에 연결해야 합니다.\n",
    "\n",
    "먼저 이 예제에 필요한 패키지를 `pip` 설치해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9Q1p2C9-wce",
    "outputId": "204d5aee-571e-4363-be6e-f87d058f2d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (8.9.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from elasticsearch) (8.4.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.16)\n",
      "Requirement already satisfied: certifi in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.7.22)\n",
      "Requirement already satisfied: sentence_transformers in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (4.32.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (1.11.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.3)\n",
      "Requirement already satisfied: click in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torchvision->sentence_transformers) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: torch in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\refar\\.conda\\envs\\es\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch\n",
    "!pip install sentence_transformers\n",
    "!pip install torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzq2Z1wBs3M"
   },
   "source": [
    "다음으로 `elasticsearch` 모듈과 `getpass` 모듈을 가져와야 합니다.\n",
    "`getpass`는 Python 표준 라이브러리의 일부이며 자격 증명을 안전하게 요청하는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 경로가 이미 존재합니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "try :\n",
    "    os.mkdir(cwd + \"/models\") \n",
    "except:\n",
    "    print('해당 경로가 이미 존재합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd + \"/models\")\n",
    "\n",
    "try :\n",
    "    os.system(\"git clone https://huggingface.co/intfloat/multilingual-e5-base\")\n",
    "except:\n",
    "    print('해당 경로가 이미 존재합니다.')\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uP_GTVRi-d96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\refar\\.conda\\envs\\es\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import textwrap\n",
    "import torch\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model = SentenceTransformer(cwd + '/models/multilingual-e5-base', device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AMSePFiZCRqX"
   },
   "source": [
    "이제 Python Elasticsearch 클라이언트를 인스턴스화할 수 있습니다.\n",
    "먼저 사용자에게 비밀번호와 Cloud ID를 묻는 메시지를 표시합니다.\n",
    "\n",
    "🔐 참고: `getpass`를 사용하면 자격 증명을 터미널에 표시하거나 메모리에 저장하지 않고 사용자에게 자격 증명을 안전하게 묻는 메시지를 표시할 수 있습니다.\n",
    "\n",
    "그런 다음 `Elasticsearch` 클래스의 인스턴스를 인스턴스화하는 `클라이언트` 개체를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0MdAZ53CdKL",
    "outputId": "96ea6f81-f935-4d51-c4a7-af5a896180f1"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "ES_URL = input('Elasticsearch URL: ')\n",
    "ES_ID = \"elastic\" \n",
    "ES_PW = getpass('elastic user PW: ')\n",
    "CERT_PATH = input('Elasticsearch cer 파일 경로: ')\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    ES_URL,\n",
    "    basic_auth=(ES_ID, ES_PW),\n",
    "    ca_certs=CERT_PATH\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bRHbecNeEDL3"
   },
   "source": [
    "Confirm that the client has connected with this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdiUKqZbEKfF",
    "outputId": "43b6f1cd-a43e-4dbe-caa5-7fd170464881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'NOTESWEETHOME', 'cluster_name': 'elasticsearch', 'cluster_uuid': 'L4MsufEIRvWXg2zAaORhYw', 'version': {'number': '8.9.1', 'build_flavor': 'default', 'build_type': 'zip', 'build_hash': 'a813d015ef1826148d9d389bd1c0d781c6e349f0', 'build_date': '2023-08-10T05:02:32.517455352Z', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "print(client.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "enHQuT57DhD1"
   },
   "source": [
    "Refer to https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect to a self-managed deployment.\n",
    "\n",
    "Read https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect using API keys.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TF_wxIAhD07a"
   },
   "source": [
    "# Create Elasticsearch index with required mappings\n",
    "\n",
    "We need to add a field to support dense vector storage and search.\n",
    "Note the `passage_embedding` field below, which is used to store the dense vector representation of the `passage` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvYECABJJs_2",
    "outputId": "18fb51e4-c4f6-4d1b-cb2d-bc6f8ec1aa84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\refar\\AppData\\Local\\Temp\\ipykernel_12388\\1528644730.py:21: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  client.indices.create(index=\"articles\", body=mapping)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'articles'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the mapping\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"language\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"passage\": {\"type\": \"text\"},\n",
    "            \"passage_embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": \"true\",\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the index (deleting any existing index)\n",
    "client.indices.delete(index=\"articles\", ignore_unavailable=True)\n",
    "client.indices.create(index=\"articles\", body=mapping)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Let's index some data.\n",
    "Note that we are embedding the `passage` field using the sentence transformer model.\n",
    "Once indexed, you'll see that your documents contain a `passage_embedding` field (`\"type\": \"dense_vector\"`) which contains a vector of floating point values.\n",
    "This is the embedding of the `passage` field in vector space.\n",
    "We'll use this field to perform semantic search using kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    {\n",
    "        \"language\": \"en\",\n",
    "        \"id\": \"1643584#0\",\n",
    "        \"title\": \"Bloor Street\",\n",
    "        \"passage\": \"\"\"Bloor Street is a major east–west residential and commercial thoroughfare in Toronto, Ontario, Canada. Bloor Street runs from the Prince Edward Viaduct, which spans the Don River Valley, westward into Mississauga where it ends at Central Parkway. East of the viaduct, Danforth Avenue continues along the same right-of-way. The street, approximately long, contains a significant cross-sample of Toronto's ethnic communities. It is also home to Toronto's famous shopping street, the Mink Mile.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"language\": \"en\",\n",
    "        \"id\": \"2190499#0\",\n",
    "        \"title\": \"Elphinstone College\",\n",
    "        \"passage\": \"\"\"Elphinstone College is an institution of higher education affiliated to the University of Mumbai. Established in 1856, it is one of the oldest colleges of the University of Mumbai. It is reputed for producing luminaries like Bal Gangadhar Tilak, Bhim Rao Ambedkar, Virchand Gandhi, Badruddin Tyabji, Pherozshah Mehta, Kashinath Trimbak Telang, Jamsetji Tata and for illustrious professors that includes Dadabhai Naoroji. It is further observed for having played a key role in spread of Western education in the Bombay Presidency.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"language\": \"en\",\n",
    "        \"id\": \"8881#0\",\n",
    "        \"title\": \"Doctor (title)\",\n",
    "        \"passage\": \"\"\"Doctor is an academic title that originates from the Latin word of the same spelling and meaning. The word is originally an agentive noun of the Latin verb \"\" 'to teach'. It has been used as an academic title in Europe since the 13th century, when the first Doctorates were awarded at the University of Bologna and the University of Paris. Having become established in European universities, this usage spread around the world. Contracted \"Dr\" or \"Dr.\", it is used as a designation for a person who has obtained a Doctorate (e.g. PhD). In many parts of the world it is also used by medical practitioners, regardless of whether or not they hold a doctoral-level degree.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"language\": \"de\",\n",
    "        \"id\": \"9002#0\",\n",
    "        \"title\": \"Gesundheits- und Krankenpflege\",\n",
    "        \"passage\": \"\"\"Die Gesundheits- und Krankenpflege als Berufsfeld umfasst die Versorgung und Betreuung von Menschen aller Altersgruppen, insbesondere kranke, behinderte und sterbende Erwachsene. Die Gesundheits- und Kinderkrankenpflege hat ihren Schwerpunkt in der Versorgung von Kindern und Jugendlichen. In beiden Fachrichtungen gehört die Verhütung von Krankheiten und Gesunderhaltung zum Aufgabengebiet der professionellen Pflege.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"language\": \"de\",\n",
    "        \"id\": \"7769762#0\",\n",
    "        \"title\": \"Tourismusregion (Österreich)\",\n",
    "        \"passage\": \"\"\"Unter Tourismusregion versteht man in Österreich die in den Landestourismusgesetzen verankerten Tourismusverbände mehrerer Gemeinden, im weiteren Sinne aller Gebietskörperschaften.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"language\": \"de\",\n",
    "        \"id\": \"2270104#0\",\n",
    "        \"title\": \"London Wall\",\n",
    "        \"passage\": \"\"\"London Wall ist die strategische Stadtmauer, die die Römer um Londinium gebaut haben, um die Stadt zu schützen, die über den wichtigen Hafen an der Themse verfügte. Bis ins späte Mittelalter hinein bildete diese Stadtmauer die Grenzen von London. Heute ist \"London Wall\" auch der Name einer Straße, die an einem noch bestehenden Abschnitt der Stadtmauer verläuft.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"language\": \"de\",\n",
    "        \"id\": \"2270104#1\",\n",
    "        \"title\": \"London Wall\",\n",
    "        \"passage\": \"\"\"Die Mauer wurde Ende des zweiten oder Anfang des dritten Jahrhunderts erbaut, wahrscheinlich zwischen 190 und 225, vermutlich zwischen 200 und 220. Sie entstand somit etwa achtzig Jahre nach dem im Jahr 120 erfolgten Bau der Festung, deren nördliche und westliche Mauern verstärkt und in der Höhe verdoppelt wurden, um einen Teil der neuen Stadtmauer zu bilden. Die Anlage wurde zumindest bis zum Ende des vierten Jahrhunderts weiter ausgebaut. Sie zählt zu den letzten großen Bauprojekten der Römer vor deren Rückzug aus Britannien im Jahr 410.\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index documents\n",
    "\n",
    "Our dataset is a Python list that contains dictionaries of passages from Wikipedia articles in two languages.\n",
    "We'll use the `helpers.bulk` method to index our documents in batches.\n",
    "\n",
    "The following code iterates over the articles and creates a list of actions to be performed.\n",
    "Each action is a dictionary containing an \"index\" operation on our Elasticsearch index.\n",
    "The passage is encoded using our selected model, and the encoded vector is added to the article document.\n",
    "Note that the E5 models require that a prefix instruction is used \"passage: \" to tell the model that it is to embed a passage.\n",
    "On the query side, the query string will be prefixed with \"query: \".\n",
    "The article document is then added to the list of actions.\n",
    "\n",
    "Finally, we call the `bulk` method, specifying the index name and the list of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 88, 'errors': False, 'items': [{'index': {'_index': 'articles', '_id': 'u041a4oBUud9ZBdrK8va', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'articles', '_id': 'vE41a4oBUud9ZBdrK8vc', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'articles', '_id': 'vU41a4oBUud9ZBdrK8vc', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 2, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'articles', '_id': 'vk41a4oBUud9ZBdrK8vc', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 3, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'articles', '_id': 'v041a4oBUud9ZBdrK8vc', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 4, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'articles', '_id': 'wE41a4oBUud9ZBdrK8vc', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 5, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'articles', '_id': 'wU41a4oBUud9ZBdrK8vc', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 6, '_primary_term': 1, 'status': 201}}]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = []\n",
    "for article in articles:\n",
    "    actions.append({\"index\": {\"_index\": \"articles\"}})\n",
    "    passage = article[\"passage\"]\n",
    "    passageEmbedding = model.encode(f\"passage: {passage}\").tolist()\n",
    "    article[\"passage_embedding\"] = passageEmbedding\n",
    "    actions.append(article)\n",
    "\n",
    "client.bulk(index=\"articles\", operations=actions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MrBCHdH1u8Wd"
   },
   "source": [
    "# Multilingual Semantic Search\n",
    "\n",
    "In the following, we will search using two kinds of queries:\n",
    " * Query in English to find documents in any language\n",
    " * Query in German to find documents in German only (using a filter),\n",
    "   to show the model's capabilities in non-English languages\n",
    "\n",
    "Note again that the query is prefixed with \"query: \", which the model requires to encode the query properly.\n",
    "\n",
    "A quick translation for those unfamiliar with German:\n",
    " * \"health\" -> \"Gesundheit\"\n",
    " * \"wall\" -> \"Mauer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_response(response):\n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        score = hit[\"_score\"]\n",
    "        language = hit[\"_source\"][\"language\"]\n",
    "        id = hit[\"_source\"][\"id\"]\n",
    "        title = hit[\"_source\"][\"title\"]\n",
    "        passage = hit[\"_source\"][\"passage\"]\n",
    "        print()\n",
    "        print(f\"ID: {id}\")\n",
    "        print(f\"Language: {language}\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Passage: {textwrap.fill(passage, 120)}\")\n",
    "        print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(q, language=None):\n",
    "    knn = {\n",
    "        \"field\": \"passage_embedding\",\n",
    "        \"query_vector\" : model.encode(f\"query: {q}\").tolist(),\n",
    "        \"k\": 2,\n",
    "        \"num_candidates\": 5\n",
    "    }\n",
    "\n",
    "    if language:\n",
    "        knn[\"filter\"] = {\n",
    "            \"term\": {\n",
    "                \"language\": language,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return client.search(index=\"articles\", knn=knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: 9002#0\n",
      "Language: de\n",
      "Title: Gesundheits- und Krankenpflege\n",
      "Passage: Die Gesundheits- und Krankenpflege als Berufsfeld umfasst die Versorgung und Betreuung von Menschen aller Altersgruppen,\n",
      "insbesondere kranke, behinderte und sterbende Erwachsene. Die Gesundheits- und Kinderkrankenpflege hat ihren Schwerpunkt\n",
      "in der Versorgung von Kindern und Jugendlichen. In beiden Fachrichtungen gehört die Verhütung von Krankheiten und\n",
      "Gesunderhaltung zum Aufgabengebiet der professionellen Pflege.\n",
      "Score: 0.8986237\n",
      "\n",
      "ID: 8881#0\n",
      "Language: en\n",
      "Title: Doctor (title)\n",
      "Passage: Doctor is an academic title that originates from the Latin word of the same spelling and meaning. The word is originally\n",
      "an agentive noun of the Latin verb \"\" 'to teach'. It has been used as an academic title in Europe since the 13th\n",
      "century, when the first Doctorates were awarded at the University of Bologna and the University of Paris. Having become\n",
      "established in European universities, this usage spread around the world. Contracted \"Dr\" or \"Dr.\", it is used as a\n",
      "designation for a person who has obtained a Doctorate (e.g. PhD). In many parts of the world it is also used by medical\n",
      "practitioners, regardless of whether or not they hold a doctoral-level degree.\n",
      "Score: 0.89126825\n"
     ]
    }
   ],
   "source": [
    "pretty_response(query(\"health\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the results above, we see that the document about healthcare,\n",
    "even though it's in German, matches better to the query \"health\",\n",
    "versus the English document which doesn't talk about health specifically but about doctors more generally.\n",
    "This is the power of a multilingual embedding which embeds meaning across languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: 2270104#0\n",
      "Language: de\n",
      "Title: London Wall\n",
      "Passage: London Wall ist die strategische Stadtmauer, die die Römer um Londinium gebaut haben, um die Stadt zu schützen, die über\n",
      "den wichtigen Hafen an der Themse verfügte. Bis ins späte Mittelalter hinein bildete diese Stadtmauer die Grenzen von\n",
      "London. Heute ist \"London Wall\" auch der Name einer Straße, die an einem noch bestehenden Abschnitt der Stadtmauer\n",
      "verläuft.\n",
      "Score: 0.8941859\n",
      "\n",
      "ID: 2270104#1\n",
      "Language: de\n",
      "Title: London Wall\n",
      "Passage: Die Mauer wurde Ende des zweiten oder Anfang des dritten Jahrhunderts erbaut, wahrscheinlich zwischen 190 und 225,\n",
      "vermutlich zwischen 200 und 220. Sie entstand somit etwa achtzig Jahre nach dem im Jahr 120 erfolgten Bau der Festung,\n",
      "deren nördliche und westliche Mauern verstärkt und in der Höhe verdoppelt wurden, um einen Teil der neuen Stadtmauer zu\n",
      "bilden. Die Anlage wurde zumindest bis zum Ende des vierten Jahrhunderts weiter ausgebaut. Sie zählt zu den letzten\n",
      "großen Bauprojekten der Römer vor deren Rückzug aus Britannien im Jahr 410.\n",
      "Score: 0.87009525\n"
     ]
    }
   ],
   "source": [
    "pretty_response(query(\"wall\", language=\"de\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: 2270104#1\n",
      "Language: de\n",
      "Title: London Wall\n",
      "Passage: Die Mauer wurde Ende des zweiten oder Anfang des dritten Jahrhunderts erbaut, wahrscheinlich zwischen 190 und 225,\n",
      "vermutlich zwischen 200 und 220. Sie entstand somit etwa achtzig Jahre nach dem im Jahr 120 erfolgten Bau der Festung,\n",
      "deren nördliche und westliche Mauern verstärkt und in der Höhe verdoppelt wurden, um einen Teil der neuen Stadtmauer zu\n",
      "bilden. Die Anlage wurde zumindest bis zum Ende des vierten Jahrhunderts weiter ausgebaut. Sie zählt zu den letzten\n",
      "großen Bauprojekten der Römer vor deren Rückzug aus Britannien im Jahr 410.\n",
      "Score: 0.88160396\n",
      "\n",
      "ID: 2270104#0\n",
      "Language: de\n",
      "Title: London Wall\n",
      "Passage: London Wall ist die strategische Stadtmauer, die die Römer um Londinium gebaut haben, um die Stadt zu schützen, die über\n",
      "den wichtigen Hafen an der Themse verfügte. Bis ins späte Mittelalter hinein bildete diese Stadtmauer die Grenzen von\n",
      "London. Heute ist \"London Wall\" auch der Name einer Straße, die an einem noch bestehenden Abschnitt der Stadtmauer\n",
      "verläuft.\n",
      "Score: 0.8761393\n"
     ]
    }
   ],
   "source": [
    "pretty_response(query(\"Mauer\", language=\"de\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
