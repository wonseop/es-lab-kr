{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tZnIXBfrRpex"
      },
      "source": [
        "# Question Answering with Langchain and Mistral\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/generative-ai/question-answering.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "이 대화형 노트북은 Langchain을 사용하여 가상의 직장 문서를 구절로 분할하고 \"multilingual-e5-base\"를 사용하여 이러한 구절을 임베딩으로 변환하고 Elasticsearch에 저장합니다.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "그런 다음 질문을 하면 벡터 스토어에서 관련 구절을 검색하고 langchain과 Mistral LLM을 사용하여 질문에 대한 요약을 제공합니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GyAst2W-VpHb"
      },
      "source": [
        "## Install packages and import modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "33A-cP-XvFCr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (4.7.1)\n",
            "Requirement already satisfied: langchain in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (0.0.344)\n",
            "Requirement already satisfied: elasticsearch in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (8.11.0)\n",
            "Requirement already satisfied: tiktoken in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (0.5.1)\n",
            "Requirement already satisfied: sentence_transformers in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: llama-cpp-python in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (0.2.20)\n",
            "Requirement already satisfied: wget in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (3.2)\n",
            "Requirement already satisfied: pyopenssl in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (23.3.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (5.2.0)\n",
            "Requirement already satisfied: fastapi in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.104.1)\n",
            "Requirement already satisfied: ffmpy in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.7.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.7.0)\n",
            "Requirement already satisfied: httpx in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.25.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.19.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (3.8.2)\n",
            "Requirement already satisfied: numpy~=1.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (1.26.2)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (3.9.10)\n",
            "Requirement already satisfied: packaging in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (10.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (2.5.2)\n",
            "Requirement already satisfied: pydub in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (4.8.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio) (0.24.0.post1)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio-client==0.7.0->gradio) (2023.10.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from gradio-client==0.7.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: anyio<4.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.8 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from langchain) (0.0.8)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from langchain) (0.0.66)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from elasticsearch) (8.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from tiktoken) (2023.10.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sentence_transformers) (2.1.1)\n",
            "Requirement already satisfied: torchvision in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sentence_transformers) (0.16.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: cryptography<42,>=41.0.5 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from pyopenssl) (41.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\n",
            "Requirement already satisfied: toolz in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from anyio<4.0->langchain) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from cryptography<42,>=41.0.5->pyopenssl) (1.16.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch) (2.1.0)\n",
            "Requirement already satisfied: certifi in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.11.17)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.5 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from pydantic>=2.0->gradio) (2.14.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sympy in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: joblib in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pycparser in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from cffi>=1.12->cryptography<42,>=41.0.5->pyopenssl) (2.21)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\miniconda3\\envs\\chatbot11\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# install packages\n",
        "%pip install -U gradio langchain elasticsearch tiktoken sentence_transformers llama-cpp-python wget pyopenssl "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import modules\n",
        "from getpass import getpass\n",
        "from langchain import PromptTemplate\n",
        "from langchain.vectorstores import ElasticsearchStore\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from urllib.request import urlopen\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "import json\n",
        "import os\n",
        "import wget\n",
        "\n",
        "cwd = os.getcwd()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qtEOCsCLWCZp"
      },
      "source": [
        "## Connect to Elasticsearch\n",
        "\n",
        "[ElasticsearchStore](https://api.python.langchain.com/en/latest/Vectorstores/langchain.Vectorstores.elasticsearch.ElasticsearchStore.html)를 사용하여 Elastic Cloud 배포에 연결하겠습니다. 이렇게 하면 데이터를 쉽게 생성하고 색인화하는 데 도움이 됩니다. \n",
        "\n",
        "ElasticsearchStore 인스턴스에서 임베딩을 [HuggingFaceEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html)로 설정하여 해당 텍스트와 Elasticsearch 인덱스 이름을 임베드합니다. 임베딩 모델은 [intfloat/multilingual-e5-base](https://huggingface.co/intfloat/multilingual-e5-base) 모델을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a-t1mglib54F"
      },
      "outputs": [],
      "source": [
        "# set elastic client info\n",
        "ES_URL = input('Elasticsearch URL(ex:https://127.0.0.1:9200): ')\n",
        "ES_USER = \"elastic\" \n",
        "ES_USER_PASSWORD = getpass('elastic user PW: ')\n",
        "CERT_PATH = input('Elasticsearch pem 파일 경로: ')\n",
        "# pem 생성 방법: https://cdax.ch/2022/02/20/elasticsearch-python-workshop-1-the-basics/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "client = Elasticsearch(\n",
        "    ES_URL,\n",
        "    basic_auth=(ES_USER, ES_USER_PASSWORD),\n",
        "    ca_certs=CERT_PATH\n",
        ")\n",
        "\n",
        "if client.indices.exists(index=\"workplace_index\"):\n",
        "    client.indices.delete(index=\"workplace_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "\n",
        "if os.path.isdir(cwd + \"/models\"):\n",
        "    pass\n",
        "else:\n",
        "    os.mkdir(cwd + \"/models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(cwd + \"/models\")\n",
        "\n",
        "try :\n",
        "    os.system(\"git lfs install & git clone https://huggingface.co/intfloat/multilingual-e5-base\")\n",
        "except:\n",
        "    print('이미 모델이 존재합니다.')\n",
        "\n",
        "os.chdir(cwd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=cwd + \"/models/multilingual-e5-base\", model_kwargs = {'device': 'cpu'} )\n",
        "\n",
        "vector_store = ElasticsearchStore(\n",
        "    es_connection = client,\n",
        "    index_name=\"workplace_index\",\n",
        "    embedding=embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the dataset \n",
        "\n",
        "샘플 데이터 세트를 다운로드하고 문서를 역직렬화해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J8-93TiJsNyK"
      },
      "outputs": [],
      "source": [
        "response = open(cwd + \"/data/data.json\")\n",
        "\n",
        "workplace_docs = json.loads(response.read())\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p0cQFDl1b9v4"
      },
      "source": [
        "### Split Documents into Passages\n",
        "\n",
        "검색 특이성(retrieval specificity)을 향상하고 최종 질문 답변 프롬프트의 컨텍스트 창 내에서 여러 구절을 제공할 수 있도록 문서를 구절로 청크할 것입니다.\n",
        "\n",
        "여기서는 400개의 토큰이 겹치는 800개의 토큰 구절로 문서를 청크합니다.\n",
        "\n",
        "여기서는 간단한 스플리터를 사용하고 있지만 Langchain은 컨텍스트 손실 가능성을 줄이기 위해 고급 스플리터를 제공합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dbHEoTF6vBXE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created a chunk of size 866, which is longer than the specified 800\n",
            "Created a chunk of size 1120, which is longer than the specified 800\n"
          ]
        }
      ],
      "source": [
        "metadata = []\n",
        "content = []\n",
        "\n",
        "for doc in workplace_docs:\n",
        "  content.append(doc[\"content\"])\n",
        "  metadata.append({\n",
        "      \"name\": doc[\"name\"],\n",
        "      \"summary\": doc[\"summary\"]\n",
        "  })\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=400)\n",
        "docs = text_splitter.create_documents(content, metadatas=metadata)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RmCUl0hxW4lG"
      },
      "source": [
        "## Index data into elasticsearch\n",
        "\n",
        "이제 각 문서를 800개의 청크 크기로 분할했으므로 이제 [ElasticsearchStore.from_documents](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html#langchain.vectorstores.elasticsearch.ElasticsearchStore.from_documents)를 사용하여 Elasticsearch에 데이터를 인덱싱하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = vector_store.from_documents(\n",
        "    docs, \n",
        "    embeddings, \n",
        "    es_connection=client, \n",
        "    index_name=\"workplace_index\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rXJH_MiWejv7"
      },
      "source": [
        "## Asking a question\n",
        "\n",
        "이제 Elasticsearch에 구절이 저장되었으므로 관련 구절을 얻기 위해 질문을 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wget\n",
        "\n",
        "if os.path.isfile(cwd + \"/models/ggml-model-q4_0.gguf\"):\n",
        "    pass\n",
        "else:\n",
        "    wget.download(\n",
        "        # \"https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q3_K_M.gguf\",\n",
        "        \"https://huggingface.co/davidkim205/komt-mistral-7b-v1-gguf/resolve/main/ggml-model-q4_0.gguf\",\n",
        "        out=cwd + \"/models/ggml-model-q4_0.gguf\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OobeBT6rek7Q",
        "outputId": "ba7b3a7a-253e-4e7f-83b9-cec07ebdac09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "n_gpu_layers = None  # Metal set to 1 is enough.\n",
        "n_batch = 52  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "from langchain.llms import HuggingFaceTextGenInference\n",
        "\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    # https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13-GGUF\n",
        "    model_path = cwd + \"/models/ggml-model-q4_0.gguf\",\n",
        "    n_gpu_layers=n_gpu_layers,\n",
        "    n_batch=n_batch,\n",
        "    n_ctx=2048,\n",
        "\n",
        "    # https://www.reddit.com/r/LocalLLaMA/comments/1343bgz/what_model_parameters_is_everyone_using/\n",
        "    temperature=0.8,\n",
        "    top_k=1,\n",
        "    top_p=0.2,\n",
        "\n",
        "    max_tokens=1024,\n",
        "    verbose=True,\n",
        "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
        "    callback_manager=callback_manager,\n",
        "    repeat_penalty=1.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NASA stands for North America South America region.---- Answer ----\n",
            " NASA stands for North America South America region.\n",
            "---- Sources ----\n",
            "Sales Organization Overview\n",
            "Our sales organization is structured to effectively serve our customers and achieve our business objectives across multiple regions. The organization is divided into the following main regions:\n",
            "\n",
            "The Americas: This region includes the United States, Canada, Mexico, as well as Central and South America. The North America South America region (NASA) has two Area Vice-Presidents: Laura Martinez is the Area Vice-President of North America, and Gary Johnson is the Area Vice-President of South America.\n",
            "New Employee Onboarding Guide\n",
            "Welcome to our team! We are excited to have you on board and look forward to your valuable contributions. This onboarding guide is designed to help you get started by providing essential information about our policies, procedures, and resources. Please read through this guide carefully and reach out to the HR department if you have any questions.\n",
            "Introduction to Our Company Culture and Values\n",
            "Our company is committed to creating a diverse, inclusive, and supportive work environment. We believe that our employees are our most valuable asset and strive to foster a culture of collaboration, innovation, and continuous learning. Our core values include:\n",
            "Integrity: We act ethically and honestly in all our interactions.\n",
            "Teamwork: We work together to achieve common goals and support each other's growth.\n",
            "Excellence: We strive for the highest quality in our products, services, and relationships.\n",
            "Innovation: We encourage creativity and embrace change to stay ahead in the market.\n",
            "Respect: We treat each other with dignity and value the unique perspectives of all our colleagues.\n",
            "Key Onboarding Steps\n",
            "To ensure a smooth onboarding process, please complete the following steps within your first week:\n",
            "Attend orientation: You will be invited to an orientation session to meet your colleagues and learn more about our company's history, mission, and values.\n",
            "Review policies and procedures: Familiarize yourself with our employee handbook, which contains important information about our policies and procedures. Please read it thoroughly and adhere to the guidelines.\n",
            "Complete required training: You may be required to complete mandatory training sessions, such as safety training or anti-harassment training. Ensure that you attend and complete these sessions as soon as possible.\n",
            "Updating Tax Elections and Documents\n",
            "It is crucial to ensure your tax information is accurate and up-to-date, regardless of the country you work in. Please follow these steps to update your tax elections and documents:\n",
            "Complete tax forms: Fill out the necessary tax forms for your country or region, which determine the amount of income tax withheld from your paycheck. You should complete new tax forms if your personal or financial situation changes, such as marriage, divorce, or a change in the number of dependents.\n",
            "Submit regional tax forms: Depending on your location, you may be required to complete additional regional or local tax forms. Check with the HR department to determine which forms are necessary.\n",
            "Update your address: If you move, make sure to update your address with the HR department to ensure accurate tax reporting.\n",
            "Benefits Enrollment\n",
            "As a new employee, you are eligible for various benefits, including health insurance, retirement plans, and paid time off. You will receive detailed information about our benefits package during orientation. To enroll in the benefits, please follow these steps:\n",
            "Review benefits options: Carefully review the benefits package and choose the options that best meet your needs.\n",
            "Complete enrollment forms: Fill out the necessary forms to enroll in your chosen benefits. Submit these forms to the HR department within 30 days of your start date.\n",
            "Designate beneficiaries: If applicable, designate beneficiaries for your life insurance and retirement plans.\n",
            "Getting Settled in Your Workspace\n",
            "To help you feel comfortable and productive in your new workspace, take the following steps:\n",
            "Set up your workstation: Organize your desk, chair, and computer according to your preferences. If you require any additional equipment or accommodations, please contact the HR department.\n",
            "Obtain necessary supplies: Request any necessary office supplies, such as pens, notepads, or folders, from the designated supply area or by contacting the appropriate department.\n",
            "Familiarize yourself with office resources: Locate common areas, such as break rooms, restrooms, and meeting rooms. Familiarize yourself with office equipment, including printers, scanners, and telephones.\n",
            "Sales Engineering Collaboration\n",
            "a. Be prepared and understand the customer's needs and pain points.\n",
            "b. Clearly explain the technical aspects of the product or solution in a simple language that the customer can understand.\n",
            "c. Address any concerns or questions the customer may have.\n",
            "Continuous Improvement:\n",
            "Actively seek feedback from the sales team regarding product performance, customer experiences, and market trends. Use this feedback to identify areas of improvement and collaborate with other engineers to enhance the product or service offerings.\n",
            "Mutual Respect and Support:\n",
            "It is essential to treat your colleagues in the sales team with respect and professionalism. Recognize and appreciate their efforts in promoting and selling the company's products and services. In turn, the sales team should also respect and appreciate the technical expertise and knowledge of the engineering team.\n",
            "Swe Career Matrix\n",
            "Responsibilities:\n",
            "Lead the design, development, and maintenance of large-scale, mission-critical software applications and components.\n",
            "Provide technical leadership and mentorship to software engineering teams.\n",
            "Drive the adoption of advanced software development practices and technologies.\n",
            "Collaborate with product management, architecture, and other stakeholders to define and deliver strategic software initiatives.\n",
            "Identify, troubleshoot, and resolve the most complex software defects and issues.\n",
            "Create and maintain technical documentation, including architectural designs and best practice guidelines.\n",
            "Represent [Company Name] as a thought leader in the software engineering community, including speaking at conferences, publishing articles, and contributing to open-source projects.\n"
          ]
        }
      ],
      "source": [
        "ans = qa(\"What does NASA stand for?\")\n",
        "\n",
        "print(\"---- Answer ----\")\n",
        "print(ans[\"result\"])\n",
        "print(\"---- Sources ----\")\n",
        "for doc in ans[\"source_documents\"]:\n",
        "  print(doc.metadata[\"name\"])\n",
        "  print(doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NASA는 North America South America region의 일부입니다.---- Answer ----\n",
            " NASA는 North America South America region의 일부입니다.\n",
            "---- Sources ----\n",
            "Sales Organization Overview\n",
            "Our sales organization is structured to effectively serve our customers and achieve our business objectives across multiple regions. The organization is divided into the following main regions:\n",
            "\n",
            "The Americas: This region includes the United States, Canada, Mexico, as well as Central and South America. The North America South America region (NASA) has two Area Vice-Presidents: Laura Martinez is the Area Vice-President of North America, and Gary Johnson is the Area Vice-President of South America.\n",
            "Fy2024 Company Sales Strategy\n",
            "II. Focus Areas\n",
            "A. Target Markets:\n",
            "Continue to serve existing markets with a focus on high-growth industries.\n",
            "Identify and penetrate new markets with high potential for our products and services.\n",
            "\n",
            "B. Customer Segmentation:\n",
            "Strengthen relationships with key accounts and strategic partners.\n",
            "Pursue new customers in underserved market segments.\n",
            "Develop tailored offerings for different customer segments based on their needs and preferences.\n",
            "\n",
            "C. Product/Service Portfolio:\n",
            "Optimize the existing product/service portfolio by focusing on high-demand solutions.\n",
            "Develop and launch innovative products/services in emerging technology areas.\n",
            "Enhance post-sales support and customer service to improve customer satisfaction.\n",
            "Fy2024 Company Sales Strategy\n",
            "C. Product/Service Portfolio:\n",
            "Optimize the existing product/service portfolio by focusing on high-demand solutions.\n",
            "Develop and launch innovative products/services in emerging technology areas.\n",
            "Enhance post-sales support and customer service to improve customer satisfaction.\n",
            "\n",
            "III. Action Plans\n",
            "A. Sales Team Development:\n",
            "Expand the sales team to cover new markets and industries.\n",
            "Provide ongoing training to sales staff on product knowledge, sales techniques, and industry trends.\n",
            "Implement a performance-based incentive system to reward top performers.\n",
            "Fy2024 Company Sales Strategy\n",
            "C. Partner Ecosystem:\n",
            "Strengthen existing partnerships and establish new strategic alliances to expand market reach.\n",
            "Collaborate with partners on joint marketing and sales initiatives.\n",
            "Provide partner training and support to ensure they effectively represent our products and services.\n",
            "\n",
            "D. Customer Success:\n",
            "Implement a proactive customer success program to improve customer retention and satisfaction.\n",
            "Develop a dedicated customer support team to address customer inquiries and concerns promptly.\n",
            "Collect and analyze customer feedback to identify areas for improvement in our products, services, and processes.\n"
          ]
        }
      ],
      "source": [
        "ans = qa(\"NASA는 무엇인가요?\")\n",
        "\n",
        "print(\"---- Answer ----\")\n",
        "print(ans[\"result\"])\n",
        "print(\"---- Sources ----\")\n",
        "for doc in ans[\"source_documents\"]:\n",
        "  print(doc.metadata[\"name\"])\n",
        "  print(doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "custom_template = \"\"\"You are an Hiberus Marketing Manager AI Assistant. Given the\n",
        "following conversation and a follow up question, rephrase the follow up question\n",
        "to be a standalone question. At the end of standalone question add this\n",
        "'Answer the question in English language.' If you do not know the answer reply with 'I am sorry, I dont have enough information'.\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\n",
        "\"\"\"\n",
        "\n",
        "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def querying(query, history):\n",
        "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "  qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "      llm=llm,\n",
        "      retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}),\n",
        "      memory=memory,\n",
        "      condense_question_prompt=CUSTOM_QUESTION_PROMPT,\n",
        "  )\n",
        "\n",
        "  result = qa_chain({\"question\": query})\n",
        "  return result[\"answer\"].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Caching examples at: 'D:\\Projects\\es-lab-kr\\notebooks\\generative-ai\\gradio_cached_examples\\16'\n",
            "Caching example 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hiberus has created the GenAI Ecosystem to expand market reach, collaborate with partners on joint marketing and sales initiatives, and provide partner training and support to ensure effective representation of their products and services.Caching example 2/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I'm sorry, but the given context does not mention anything about a \"GenAI Ecosystem.\"Running on local URL:  http://127.0.0.1:7860\n"
          ]
        },
        {
          "ename": "ProxyError",
          "evalue": "HTTPConnectionPool(host='proxy.score', port=8080): Max retries exceeded with url: http://172.21.135.237 (Caused by ProxyError('Unable to connect to proxy', RemoteDisconnected('Remote end closed connection without response')))",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1379\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteDisconnected(\u001b[39m\"\u001b[39m\u001b[39mRemote end closed connection without\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39m response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "\u001b[1;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mProxyError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;31mProxyError\u001b[0m: ('Unable to connect to proxy', RemoteDisconnected('Remote end closed connection without response'))",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\urllib3\\connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[1;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    846\u001b[0m )\n\u001b[0;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\urllib3\\util\\retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
            "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='proxy.score', port=8080): Max retries exceeded with url: http://172.21.135.237 (Caused by ProxyError('Unable to connect to proxy', RemoteDisconnected('Remote end closed connection without response')))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mProxyError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32md:\\Projects\\es-lab-kr\\notebooks\\generative-ai\\question-answering_mistral.ipynb 셀 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/es-lab-kr/notebooks/generative-ai/question-answering_mistral.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgr\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/es-lab-kr/notebooks/generative-ai/question-answering_mistral.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m iface \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39mChatInterface(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/es-lab-kr/notebooks/generative-ai/question-answering_mistral.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     fn \u001b[39m=\u001b[39m querying,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/es-lab-kr/notebooks/generative-ai/question-answering_mistral.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     chatbot\u001b[39m=\u001b[39mgr\u001b[39m.\u001b[39mChatbot(height\u001b[39m=\u001b[39m\u001b[39m600\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/es-lab-kr/notebooks/generative-ai/question-answering_mistral.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/es-lab-kr/notebooks/generative-ai/question-answering_mistral.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/es-lab-kr/notebooks/generative-ai/question-answering_mistral.ipynb#X34sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m iface\u001b[39m.\u001b[39;49mlaunch(share\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\gradio\\blocks.py:1907\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[1;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, _frontend)\u001b[0m\n\u001b[0;32m   1902\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_queue\u001b[39m.\u001b[39mset_server_app(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_app)\n\u001b[0;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wasm_utils\u001b[39m.\u001b[39mIS_WASM:\n\u001b[0;32m   1905\u001b[0m     \u001b[39m# Cannot run async functions in background other than app's scope.\u001b[39;00m\n\u001b[0;32m   1906\u001b[0m     \u001b[39m# Workaround by triggering the app endpoint\u001b[39;00m\n\u001b[1;32m-> 1907\u001b[0m     requests\u001b[39m.\u001b[39;49mget(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_url\u001b[39m}\u001b[39;49;00m\u001b[39mstartup-events\u001b[39;49m\u001b[39m\"\u001b[39;49m, verify\u001b[39m=\u001b[39;49mssl_verify)\n\u001b[0;32m   1908\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1909\u001b[0m     \u001b[39m# NOTE: One benefit of the code above dispatching `startup_events()` via a self HTTP request is\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     \u001b[39m# that `self._queue.start()` is called in another thread which is managed by the HTTP server, `uvicorn`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1913\u001b[0m     \u001b[39m# In contrast, in the Wasm env, we can't do that because `threading` is not supported and all async tasks will run in the same event loop, `pyodide.webloop.WebLoop` in the main thread.\u001b[39;00m\n\u001b[0;32m   1914\u001b[0m     \u001b[39m# So we need to manually cancel them. See `self.close()`..\u001b[39;00m\n\u001b[0;32m   1915\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstartup_events()\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\sessions.py:725\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    723\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 725\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;49;00m resp \u001b[39min\u001b[39;49;00m gen]\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     history \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\sessions.py:725\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    723\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 725\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;49;00m resp \u001b[39min\u001b[39;49;00m gen]\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     history \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\sessions.py:266\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[39myield\u001b[39;00m req\n\u001b[0;32m    264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\n\u001b[0;32m    267\u001b[0m         req,\n\u001b[0;32m    268\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    269\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    270\u001b[0m         verify\u001b[39m=\u001b[39;49mverify,\n\u001b[0;32m    271\u001b[0m         cert\u001b[39m=\u001b[39;49mcert,\n\u001b[0;32m    272\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    273\u001b[0m         allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    274\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49madapter_kwargs,\n\u001b[0;32m    275\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     extract_cookies_to_jar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcookies, prepared_request, resp\u001b[39m.\u001b[39mraw)\n\u001b[0;32m    279\u001b[0m     \u001b[39m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
            "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\chatbot11\\Lib\\site-packages\\requests\\adapters.py:513\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[39mraise\u001b[39;00m RetryError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _ProxyError):\n\u001b[1;32m--> 513\u001b[0m     \u001b[39mraise\u001b[39;00m ProxyError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m     \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n",
            "\u001b[1;31mProxyError\u001b[0m: HTTPConnectionPool(host='proxy.score', port=8080): Max retries exceeded with url: http://172.21.135.237 (Caused by ProxyError('Unable to connect to proxy', RemoteDisconnected('Remote end closed connection without response')))"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I'm sorry, but the provided context does not contain enough information to answer the question."
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "iface = gr.ChatInterface(\n",
        "    fn = querying,\n",
        "    chatbot=gr.Chatbot(height=600),\n",
        "    textbox=gr.Textbox(placeholder=\"What is GenAI Ecosystem?\", container=False, scale=7),\n",
        "    title=\"HiberusBot\",\n",
        "    theme=\"soft\",\n",
        "    examples=[\"Why Hiberus has created GenAI Ecosystem?\",\n",
        "              \"What is GenAI Ecosystem?\"],\n",
        "\n",
        "    cache_examples=True,\n",
        "    retry_btn=\"Repetir\",\n",
        "    undo_btn=\"Deshacer\",\n",
        "    clear_btn=\"Borrar\",\n",
        "    submit_btn=\"Enviar\"\n",
        "\n",
        "    )\n",
        "\n",
        "iface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
