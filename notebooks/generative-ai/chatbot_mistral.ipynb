{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with LangChain conversational chain and Mistral ü§ñüí¨\n",
    "\n",
    "Ïù¥ ÎÖ∏Ìä∏Î∂ÅÏóêÏÑúÎäî ÏÇ¨ÏóÖÏ£ºÏùò Ï†ïÏ±ÖÍ≥º Í∞ôÏùÄ ÏÇ¨Ïö©Ïûê Ï†ïÏùò Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏßàÎ¨∏Ïóê ÏùëÎãµÌï† Ïàò ÏûàÎäî Ï±óÎ¥áÏùÑ Íµ¨Ï∂ïÌïòÍ≤†ÏäµÎãàÎã§.\n",
    "\n",
    "[Mistral]() LLMÏùÄ apache-2.0 licenseÎ°ú ÏûêÏú†Î°≠Í≤å Ïù¥Ïö©Ìï† Ïàò ÏûàÏúºÎ©∞, Î≥ÑÎèÑÏùò Í≥ºÍ∏àÏù¥ ÏóÜÏäµÎãàÎã§. \n",
    "\n",
    "Ïó¨Í∏∞ÏÑúÎäî [openbuddy-mistral-7B-v13-GGUF](https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13-GGUF)Î™®Îç∏ÏùÄ Mistral Î™®Îç∏ÏùÑ ÌïúÍµ≠Ïñ¥Îì± Îã§Íµ≠Ïñ¥Î•º ÏßÄÏõêÌï† Ïàò ÏûàÎèÑÎ°ù ÌååÏù∏ÌäúÎãùÌïú Î™®Îç∏ÏûÖÎãàÎã§.\n",
    "\n",
    "Ï±óÎ¥áÏùÄ LangChainÏùò `ConversationalRetrievalChain`ÏùÑ ÏÇ¨Ïö©ÌïòÎ©∞ Îã§ÏùåÍ≥º Í∞ôÏùÄ Í∏∞Îä•ÏùÑ Í∞ñÏäµÎãàÎã§.\n",
    "\n",
    "- ÏûêÏó∞Ïñ¥Î°ú Î¨ªÎäî ÏßàÎ¨∏Ïóê ÎãµÎ≥Ä\n",
    "- ElasticsearchÏóêÏÑú ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâÏùÑ Ïã§ÌñâÌïòÏó¨ ÏßàÎ¨∏Ïóê ÎãµÌïòÎäî Î¨∏ÏÑúÎ•º Ï∞æÏúºÏÑ∏Ïöî.\n",
    "- Mistral LLMÏùÑ ÌôúÏö©ÌïòÏó¨ ÎãµÎ≥Ä Ï∂îÏ∂ú Î∞è ÏöîÏïΩ\n",
    "- ÌõÑÏÜç ÏßàÎ¨∏ÏùÑ ÏúÑÌïú ÎåÄÌôî Í∏∞Ïñµ Ïú†ÏßÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements üß∞\n",
    "\n",
    "Ïù¥ ÏòàÏóêÏÑúÎäî Îã§ÏùåÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.\n",
    "\n",
    "- Python 3.6 Ïù¥ÏÉÅ\n",
    "- Î°úÏª¨Ïóê ÏÑ§ÏπòÎêú Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages üì¶\n",
    "\n",
    "Î®ºÏ†Ä Ïù¥ ÏòàÏ†úÏóê ÌïÑÏöîÌïú Ìå®ÌÇ§ÏßÄÎ•º `pip install`Ìï©ÎãàÎã§.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (0.0.340)\n",
      "Requirement already satisfied: elasticsearch in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (8.11.0)\n",
      "Requirement already satisfied: tiktoken in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (0.5.1)\n",
      "Requirement already satisfied: sentence_transformers in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: llama-cpp-python in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (0.2.19)\n",
      "Requirement already satisfied: wget in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (3.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (3.9.0)\n",
      "Requirement already satisfied: anyio<4.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (0.6.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (0.0.66)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from elasticsearch) (8.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (0.16.1)\n",
      "Requirement already satisfied: scikit-learn in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sentence_transformers) (0.19.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from llama-cpp-python) (4.8.0)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2.1.0)\n",
      "Requirement already satisfied: certifi in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: sympy in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers) (12.3.101)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from torchvision->sentence_transformers) (10.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain elasticsearch tiktoken sentence_transformers llama-cpp-python wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize clients üîå\n",
    "\n",
    "Îã§ÏùåÏúºÎ°ú `getpass`Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÏûêÍ≤© Ï¶ùÎ™ÖÏùÑ ÏûÖÎ†•Ìï©ÎãàÎã§. `getpass`Îäî Python ÌëúÏ§Ä ÎùºÏù¥Î∏åÎü¨Î¶¨Ïùò ÏùºÎ∂ÄÏù¥Î©∞ ÏûêÍ≤© Ï¶ùÎ™ÖÏùÑ ÏïàÏ†ÑÌïòÍ≤å ÏöîÏ≤≠ÌïòÎäî Îç∞ ÏÇ¨Ïö©Îê©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "ES_URL = \"https://localhost:9200\" #input('Elasticsearch URL(ex:https://127.0.0.1:9200): ')\n",
    "ES_USER = \"elastic\" \n",
    "ES_USER_PASSWORD = \"elastic\" #getpass('elastic user PW: ')\n",
    "CERT_PATH = \"/home/wonseop/es/8.11.1/kibana-8.11.1/data/ca_1700913435542.crt\" #input('Elasticsearch pem ÌååÏùº Í≤ΩÎ°ú: ')\n",
    "# pem ÏÉùÏÑ± Î∞©Î≤ï: https://cdax.ch/2022/02/20/elasticsearch-python-workshop-1-the-basics/\n",
    "\n",
    "# set OpenAI API key\n",
    "# OPENAI_API_KEY = getpass(\"OpenAI API key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process documents üìÑ\n",
    "\n",
    "Îç∞Ïù¥ÌÑ∞Î•º Î°úÎìúÌï† ÏãúÍ∞ÑÏûÖÎãàÎã§!   \n",
    "Ïö∞Î¶¨Îäî ÏßÅÏõê Î¨∏ÏÑú Î∞è Ï†ïÏ±Ö Î™©Î°ùÏù∏ ÏßÅÏû• Í≤ÄÏÉâ ÏòàÏ†ú Îç∞Ïù¥ÌÑ∞Î•º ÏÇ¨Ïö©Ìï† Í≤ÉÏûÖÎãàÎã§.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 15 documents\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "url = cwd + \"/data/workplace-docs.json\"\n",
    "response = open(url)\n",
    "\n",
    "workplace_docs = json.loads(response.read())\n",
    "\n",
    "print(f\"Successfully loaded {len(workplace_docs)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk documents into passages ü™ì\n",
    "\n",
    "Î¥áÍ≥º Ï±ÑÌåÖÌïòÎäî ÎèôÏïà Î¥áÏùÄ Í¥ÄÎ†® Î¨∏ÏÑúÎ•º Ï∞æÍ∏∞ ÏúÑÌï¥ Ïù∏Îç±Ïä§ÏóêÏÑú ÏãúÎ©òÌã± Í≤ÄÏÉâÏùÑ Ïã§ÌñâÌï©ÎãàÎã§.   \n",
    "Ïù¥Í≤ÉÏù¥ Ï†ïÌôïÌïòÎ†§Î©¥ Ï†ÑÏ≤¥ Î¨∏ÏÑúÎ•º ÏûëÏùÄ Ï≤≠ÌÅ¨(chunk) -Íµ¨Ï†à(passage)Ïù¥ÎùºÍ≥†ÎèÑ Ìï®-Î°ú Î∂ÑÌï†Ìï¥Ïïº Ìï©ÎãàÎã§.   \n",
    "Ïù¥Îü∞ Î∞©ÏãùÏúºÎ°ú ÏùòÎØ∏Î°†Ï†Å Í≤ÄÏÉâÏùÄ Î¨∏ÏÑú ÎÇ¥ÏóêÏÑú Ïö∞Î¶¨Ïùò ÏßàÎ¨∏Ïóê Í∞ÄÏû• ÎãµÌï† Í∞ÄÎä•ÏÑ±Ïù¥ ÎÜíÏùÄ Íµ¨Ï†àÏùÑ Ï∞æÏùÑ Í≤ÉÏûÖÎãàÎã§.\n",
    "\n",
    "Ïö∞Î¶¨Îäî LangChainÏùò `CharacterTextSplitter`Î•º ÏÇ¨Ïö©ÌïòÍ≥† Î¨∏ÏÑúÏùò ÌÖçÏä§Ìä∏Î•º Ï≤≠ÌÅ¨ ÏÇ¨Ïù¥Ïóê ÏïΩÍ∞Ñ Í≤πÏπòÎèÑÎ°ù 800ÏûêÎ°ú Î∂ÑÌï†Ìï† Í≤ÉÏûÖÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 607, which is longer than the specified 512\n",
      "Created a chunk of size 788, which is longer than the specified 512\n",
      "Created a chunk of size 547, which is longer than the specified 512\n",
      "Created a chunk of size 635, which is longer than the specified 512\n",
      "Created a chunk of size 866, which is longer than the specified 512\n",
      "Created a chunk of size 619, which is longer than the specified 512\n",
      "Created a chunk of size 1120, which is longer than the specified 512\n",
      "Created a chunk of size 567, which is longer than the specified 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 15 documents into 89 passages\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "metadata = []\n",
    "content = []\n",
    "\n",
    "for doc in workplace_docs:\n",
    "    content.append(doc[\"content\"])\n",
    "    metadata.append({\n",
    "        \"name\": doc[\"name\"],\n",
    "        \"summary\": doc[\"summary\"]\n",
    "    })\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=256\n",
    ")\n",
    "docs = text_splitter.create_documents(content, metadatas=metadata)\n",
    "\n",
    "print(f\"Split {len(workplace_docs)} documents into {len(docs)} passages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\n",
    "    ES_URL,\n",
    "    basic_auth=(ES_USER, ES_USER_PASSWORD),\n",
    "    ca_certs=CERT_PATH\n",
    ")\n",
    "\n",
    "if client.indices.exists(index=\"workplace-docs\"):\n",
    "    client.indices.delete(index=\"workplace-docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÏûÑÎ≤†Îî©ÏùÑ ÏÉùÏÑ±ÌïòÍ≥† Ïù¥Î•º ÏÇ¨Ïö©ÌïòÏó¨ Î¨∏ÏÑúÎ•º Ïù∏Îç±Ïã±Ìï¥ Î≥¥Í≤†ÏäµÎãàÎã§.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "if os.path.isdir(cwd + \"/models\"):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(cwd + \"/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'multilingual-e5-base' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(cwd + \"/models\")\n",
    "\n",
    "try :\n",
    "    os.system(\"git lfs install & git clone https://huggingface.co/intfloat/multilingual-e5-base\")\n",
    "except:\n",
    "    print('Ïù¥ÎØ∏ Î™®Îç∏Ïù¥ Ï°¥Ïû¨Ìï©ÎãàÎã§.')\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n",
      "/home/wonseop/Projects/es-lab-kr/notebooks/generative-ai/models/multilingual-e5-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wonseop/miniconda3/envs/genai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import ElasticsearchStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "print(cwd + \"/models/multilingual-e5-base\")\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-base\", model_kwargs = {'device': 'cpu'} )\n",
    "embeddings = HuggingFaceEmbeddings(model_name=cwd + \"/models/multilingual-e5-base\", model_kwargs = {'device': 'cpu'} )\n",
    "\n",
    "vector_store = ElasticsearchStore.from_documents(\n",
    "    docs,\n",
    "    es_connection = client,\n",
    "    index_name=\"workplace-docs\",\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with the chatbot üí¨\n",
    "\n",
    "Ï±óÎ¥áÏùÑ Ï¥àÍ∏∞ÌôîÌï¥ Î≥¥Í≤†ÏäµÎãàÎã§.   \n",
    "ElasticsearchÎ•º Î¨∏ÏÑú Í≤ÄÏÉâ Î∞è Ï±ÑÌåÖ ÏÑ∏ÏÖò Í∏∞Î°ù Ï†ÄÏû•ÏùÑ ÏúÑÌïú Ï†ÄÏû•ÏÜåÎ°ú Ï†ïÏùòÌïòÍ≥†,   \n",
    "MistralÎ•º ÏßàÎ¨∏ÏùÑ Ìï¥ÏÑùÌïòÍ≥† ÎãµÎ≥ÄÏùÑ ÏöîÏïΩÌïòÎäî LLMÏúºÎ°ú Ï†ïÏùòÌïú Îã§Ïùå, Ïù¥Î•º ÎåÄÌôî Ï≤¥Ïù∏Ïóê Ï†ÑÎã¨Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "if os.path.isfile(cwd + \"/models/openbuddy-mistral-7b-v13.Q4_K_M.gguf\"):\n",
    "    pass\n",
    "else:\n",
    "    wget.download(\"https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13-GGUF/resolve/main/openbuddy-mistral-7b-v13.Q4_K_M.gguf\", out=cwd + \"/models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /home/wonseop/Projects/es-lab-kr/notebooks/generative-ai/models/openbuddy-mistral-7b-v13.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_K     [  4096, 36608,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:            blk.0.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:            blk.1.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:            blk.2.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:            blk.3.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:            blk.4.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:            blk.5.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.6.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.7.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.8.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.8.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.9.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.9.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.10.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:           blk.10.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.11.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.11.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:             blk.12.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:           blk.12.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:           blk.13.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:           blk.14.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:           blk.16.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:           blk.18.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:           blk.19.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:           blk.20.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:           blk.21.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.23.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:           blk.24.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.25.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_down.weight q4_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:           blk.27.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:           blk.28.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:           blk.29.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.30.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q4_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q4_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:             blk.31.ffn_up.weight q4_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:           blk.31.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:                    output.weight q6_K     [  4096, 36608,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = openbuddy_openbuddy-mistral-7b-v13\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,36608]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,36608]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,36608]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 361/36608 vs 259/36608 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 36608\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.28 B\n",
      "llm_load_print_meta: model size       = 4.09 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name   = openbuddy_openbuddy-mistral-7b-v13\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: mem required  = 4190.36 MiB\n",
      "..............................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  512.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 740/740\n",
      "llama_new_context_with_model: compute buffer total size = 7.56 MiB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "n_gpu_layers = None  # Metal set to 1 is enough.\n",
    "n_batch = 1  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    # https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13-GGUF\n",
    "    model_path = cwd + \"/models/openbuddy-mistral-7b-v13.Q4_K_M.gguf\",\n",
    "    # n_gpu_layers=n_gpu_layers,\n",
    "    # n_batch=n_batch,\n",
    "    n_ctx=4096,\n",
    "\n",
    "    # https://www.reddit.com/r/LocalLLaMA/comments/1343bgz/what_model_parameters_is_everyone_using/\n",
    "    temperature=0.75,\n",
    "    top_k=1,\n",
    "    top_p=1,\n",
    "\n",
    "    # max_tokens=2048,\n",
    "    verbose=True,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from lib.elasticsearch_chat_message_history import ElasticsearchChatMessageHistory\n",
    "from uuid import uuid4\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "chat = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "session_id = str(uuid4())\n",
    "chat_history = ElasticsearchChatMessageHistory(\n",
    "    client=vector_store.client,\n",
    "    session_id=session_id,\n",
    "    index=\"workplace-docs-chat-history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ïù¥Ï†ú Ï±óÎ¥áÏóê ÏßàÎ¨∏ÏùÑ Ìï† Ïàò ÏûàÏäµÎãàÎã§!\n",
    "\n",
    "Í∞Å ÏßàÎ¨∏Ïóê ÎåÄÌïú Ïª®ÌÖçÏä§Ìä∏Î°ú Ï±ÑÌåÖ Í∏∞Î°ùÏù¥ Ïñ¥ÎñªÍ≤å Ï†ÑÎã¨ÎêòÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CHAT SESSION ID] 3a35cfac-ad01-433f-a045-ab81180b8df8\n"
     ]
    }
   ],
   "source": [
    "# Define a convenience function for Q&A\n",
    "def ask(question, chat_history):\n",
    "    result = chat({\"question\": question, \"chat_history\": chat_history.messages})\n",
    "    print(f\"\"\"[QUESTION] {question}\n",
    "[ANSWER]  {result[\"answer\"]}\n",
    "          [SUPPORTING DOCUMENTS] {list(map(lambda d: d.metadata[\"name\"], list(result[\"source_documents\"])))}\"\"\")\n",
    "    chat_history.add_user_message(result[\"question\"])\n",
    "    chat_history.add_ai_message(result[\"answer\"])\n",
    "\n",
    "# Chat away!\n",
    "print(f\"[CHAT SESSION ID] {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° _Try experimenting with other questions or after clearing the workplace data, and observe how the responses change._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NASA stands for North America South America. It is the Area Vice-President of North America and the Area Vice-President of South America in our organization's sales structure.\n",
      "[QUESTION] What does NASA stand for?\n",
      "[ANSWER]   NASA stands for North America South America. It is the Area Vice-President of North America and the Area Vice-President of South America in our organization's sales structure.\n",
      "\n",
      "          [SUPPORTING DOCUMENTS] ['Sales Organization Overview', 'Code Of Conduct', 'Code Of Conduct', 'New Employee Onboarding Guide']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     693.17 ms\n",
      "llama_print_timings:      sample time =      18.82 ms /    39 runs   (    0.48 ms per token,  2072.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   99425.20 ms /  1157 tokens (   85.93 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4583.97 ms /    38 runs   (  120.63 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  104484.34 ms\n"
     ]
    }
   ],
   "source": [
    "ask(\"What does NASA stand for?\", chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What countries are included in the North America and South America regions according to NASA's sales structure?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     693.17 ms\n",
      "llama_print_timings:      sample time =      10.02 ms /    22 runs   (    0.46 ms per token,  2196.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8564.69 ms /   104 tokens (   82.35 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:        eval time =    2336.84 ms /    21 runs   (  111.28 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =   11016.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " According to NASA's sales structure, the North America region includes the United States, Canada, Mexico, and Central and South America. The Area Vice-President of North America is Laura Martinez, while the Area Vice-President of South America is Gary Johnson.\n",
      "[QUESTION] Which countries are part of it?\n",
      "[ANSWER]   According to NASA's sales structure, the North America region includes the United States, Canada, Mexico, and Central and South America. The Area Vice-President of North America is Laura Martinez, while the Area Vice-President of South America is Gary Johnson.\n",
      "\n",
      "          [SUPPORTING DOCUMENTS] ['Sales Organization Overview', 'Sales Organization Overview', 'Sales Organization Overview', 'Sales Engineering Collaboration']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     693.17 ms\n",
      "llama_print_timings:      sample time =      28.57 ms /    58 runs   (    0.49 ms per token,  2030.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =   43655.00 ms /   520 tokens (   83.95 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6734.35 ms /    58 runs   (  116.11 ms per token,     8.61 tokens per second)\n",
      "llama_print_timings:       total time =   50750.12 ms\n"
     ]
    }
   ],
   "source": [
    "ask(\"Which countries are part of it?\", chat_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Who are the team's leads in NASA's sales structure?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     693.17 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    16 runs   (    0.47 ms per token,  2131.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14700.83 ms /   178 tokens (   82.59 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1678.28 ms /    15 runs   (  111.89 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =   16486.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Area Vice-President of North America is Laura Martinez, while the Area Vice-President of South America is Gary Johnson. They lead the respective teams for the North and South America regions within the NASA sales structure.\n",
      "[QUESTION] Who are the team's leads?\n",
      "[ANSWER]  \n",
      "The Area Vice-President of North America is Laura Martinez, while the Area Vice-President of South America is Gary Johnson. They lead the respective teams for the North and South America regions within the NASA sales structure.\n",
      "\n",
      "          [SUPPORTING DOCUMENTS] ['Sales Organization Overview', 'Sales Engineering Collaboration', 'Sales Engineering Collaboration', 'Sales Organization Overview']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     693.17 ms\n",
      "llama_print_timings:      sample time =      24.88 ms /    50 runs   (    0.50 ms per token,  2009.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   32621.29 ms /   391 tokens (   83.43 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:        eval time =    5588.11 ms /    49 runs   (  114.04 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =   38505.83 ms\n"
     ]
    }
   ],
   "source": [
    "ask(\"Who are the team's leads?\", chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Clean up üßπ\n",
    "\n",
    "ÏôÑÎ£åÎêòÎ©¥ Ïù¥ ÏÑ∏ÏÖòÏùò Ï±ÑÌåÖ Í∏∞Î°ùÏùÑ Ï†ïÎ¶¨Ìï† Ïàò ÏûàÏäµÎãàÎã§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or delete the indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.client.indices.delete(index='workplace-docs')\n",
    "vector_store.client.indices.delete(index='workplace-docs-chat-history')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
